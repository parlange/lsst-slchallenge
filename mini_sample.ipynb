{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475abd57-899b-4f10-8a60-1c9597fb55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision timm astropy scikit-learn tqdm seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2768f0c-31a5-4cf8-854e-c9875484d261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Bitpix</th>\n",
       "      <th>NAXIS</th>\n",
       "      <th>Object</th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/metadata_c...</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/images/ima...</td>\n",
       "      <td>(20000, 61, 61)</td>\n",
       "      <td>-64</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/images/ima...</td>\n",
       "      <td>(20000, 61, 61)</td>\n",
       "      <td>-64</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/images/ima...</td>\n",
       "      <td>(20000, 61, 61)</td>\n",
       "      <td>-64</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/images/ima...</td>\n",
       "      <td>(20000, 61, 61)</td>\n",
       "      <td>-64</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/parlange/datasets/mini_sample/images/ima...</td>\n",
       "      <td>(20000, 61, 61)</td>\n",
       "      <td>-64</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File       Dimensions  Bitpix  \\\n",
       "0  /home/parlange/datasets/mini_sample/metadata_c...             None       8   \n",
       "1  /home/parlange/datasets/mini_sample/images/ima...  (20000, 61, 61)     -64   \n",
       "2  /home/parlange/datasets/mini_sample/images/ima...  (20000, 61, 61)     -64   \n",
       "3  /home/parlange/datasets/mini_sample/images/ima...  (20000, 61, 61)     -64   \n",
       "4  /home/parlange/datasets/mini_sample/images/ima...  (20000, 61, 61)     -64   \n",
       "5  /home/parlange/datasets/mini_sample/images/ima...  (20000, 61, 61)     -64   \n",
       "\n",
       "   NAXIS   Object Instrument     Date  \n",
       "0      0  Unknown    Unknown  Unknown  \n",
       "1      3  Unknown    Unknown  Unknown  \n",
       "2      3  Unknown    Unknown  Unknown  \n",
       "3      3  Unknown    Unknown  Unknown  \n",
       "4      3  Unknown    Unknown  Unknown  \n",
       "5      3  Unknown    Unknown  Unknown  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "dataset_path = '/home/parlange/datasets/mini_sample/images'\n",
    "metadata_path = '/home/parlange/datasets/mini_sample/'\n",
    "\n",
    "# Function to analyze FITS files\n",
    "def analyze_fits_files(directory):\n",
    "    fits_data = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.fits'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with fits.open(file_path) as hdul:\n",
    "                        header = hdul[0].header\n",
    "                        fits_data.append({\n",
    "                            'File': file_path,\n",
    "                            'Dimensions': hdul[0].data.shape if hdul[0].data is not None else None,\n",
    "                            'Bitpix': header.get('BITPIX'),\n",
    "                            'NAXIS': header.get('NAXIS'),\n",
    "                            'Object': header.get('OBJECT', 'Unknown'),\n",
    "                            'Instrument': header.get('INSTRUME', 'Unknown'),\n",
    "                            'Date': header.get('DATE-OBS', 'Unknown')\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    return fits_data\n",
    "\n",
    "# Analyze FITS files in both directories\n",
    "images_fits_data = analyze_fits_files(dataset_path)\n",
    "metadata_fits_data = analyze_fits_files(metadata_path)\n",
    "\n",
    "# Combine results and create a DataFrame\n",
    "fits_analysis_df = pd.DataFrame(images_fits_data)\n",
    "metadata_analysis_df = pd.DataFrame(metadata_fits_data)\n",
    "\n",
    "# Save the analysis results to a CSV file\n",
    "output_csv_path = 'fits_files_analysis.csv'\n",
    "fits_analysis_df.to_csv(output_csv_path, index=False)\n",
    "metadata_analysis_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "fits_analysis_df\n",
    "metadata_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fd516d-b03e-499f-82e7-60f71a4bf946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images DataFrame:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'images_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimages_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMetadata DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(metadata_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Images DataFrame:\")\n",
    "print(images_df['File'].head())\n",
    "\n",
    "print(\"\\nMetadata DataFrame:\")\n",
    "print(metadata_df['File'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa36131-69fd-4e89-97cf-1c45029ee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.info('/home/parlange/datasets/mini_sample/metadata_catalog.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f919027-0812-4110-bf62-aad116b23437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColDefs(\n",
      "    name = 'label'; format = 'D'\n",
      "    name = 'z_l'; format = 'D'\n",
      "    name = 'z_s'; format = 'D'\n",
      "    name = 'vel_disp'; format = 'D'\n",
      "    name = 'logM'; format = 'D'\n",
      "    name = 'theta_e'; format = 'D'\n",
      "    name = 'source_mag'; format = 'D'\n",
      "    name = 'lens_mag'; format = 'D'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hdul = fits.open('/home/parlange/datasets/mini_sample/metadata_catalog.fits')\n",
    "print(hdul[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b0e792-39c0-4687-93b4-b4bcf9c1c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/parlange/datasets/mini_sample/images/image_catalog_g.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (61, 61, 20000)   float64   \n",
      "Filename: /home/parlange/datasets/mini_sample/images/image_catalog_r.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (61, 61, 20000)   float64   \n",
      "Filename: /home/parlange/datasets/mini_sample/images/image_catalog_i.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (61, 61, 20000)   float64   \n",
      "Filename: /home/parlange/datasets/mini_sample/images/image_catalog_z.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (61, 61, 20000)   float64   \n",
      "Filename: /home/parlange/datasets/mini_sample/images/image_catalog_y.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (61, 61, 20000)   float64   \n"
     ]
    }
   ],
   "source": [
    "fits.info('/home/parlange/datasets/mini_sample/images/image_catalog_g.fits')\n",
    "fits.info('/home/parlange/datasets/mini_sample/images/image_catalog_r.fits')\n",
    "fits.info('/home/parlange/datasets/mini_sample/images/image_catalog_i.fits')\n",
    "fits.info('/home/parlange/datasets/mini_sample/images/image_catalog_z.fits')\n",
    "fits.info('/home/parlange/datasets/mini_sample/images/image_catalog_y.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2af0b7-968c-4edc-8c3d-28443f116248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters extracted and saved as '/home/parlange/datasets/mini_sample/labels_parameters.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the FITS file\n",
    "fits_file = '/home/parlange/datasets/mini_sample/metadata_catalog.fits'\n",
    "with fits.open(fits_file) as hdul:\n",
    "    # Access the table data\n",
    "    data = hdul[1].data\n",
    "\n",
    "# Convert all columns to a pandas DataFrame\n",
    "columns = data.columns.names  # Get all column names\n",
    "data_dict = {col: data[col] for col in columns}  # Extract data for all columns\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Save all parameters to a CSV file\n",
    "output_csv = '/home/parlange/datasets/mini_sample/labels_parameters.csv'\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"All parameters extracted and saved as '{output_csv}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41960bf9-936c-447f-911f-b14ea2c26bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 20 03:35:34 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| 99%   65C    P8             50W /  390W |      18MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off |   00000000:08:00.0 Off |                  N/A |\n",
      "| 83%   58C    P8             41W /  390W |      18MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3297      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A      3297      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6717b4-3041-498f-a9ea-2badff96df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import timm\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomApply\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "import pandas as pd  # For DataFrame handling\n",
    "from IPython.display import display  # For displaying DataFrames in Jupyter\n",
    "\n",
    "# Suppress potential warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def initialize_model(model_name, num_classes, pretrained=False, stochastic_depth_prob=0.1, \n",
    "                    fine_tune_mode=\"classification_head\", last_n=6):\n",
    "    \"\"\"\n",
    "    Initialize a model from the given model_name without ImageNet pretraining and\n",
    "    allow for a custom number of input channels (5).\n",
    "\n",
    "    Args:\n",
    "        model_name (str): One of [ViT, CaiT, DeiT, DeiT3, Swin, Twins_SVT, Twins_PCPVT, PiT, MLP-Mixer].\n",
    "        num_classes (int): Number of output classes.\n",
    "        pretrained (bool): Whether to load a pretrained model. Here we set it to False.\n",
    "        stochastic_depth_prob (float): The stochastic depth probability for supported models.\n",
    "        fine_tune_mode (str): 'classification_head', 'last_n_blocks', 'half', or 'all_blocks'.\n",
    "        last_n (int): Number of blocks/layers to unfreeze if using 'last_n_blocks'.\n",
    "\n",
    "    Returns:\n",
    "        model: The initialized and partially unfrozen model.\n",
    "    \"\"\"\n",
    "    def freeze_all(model):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_head(model):\n",
    "        if hasattr(model, 'head') and isinstance(model.head, nn.Module):\n",
    "            for p in model.head.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif hasattr(model, 'classifier') and isinstance(model.classifier, nn.Module):\n",
    "            for p in model.classifier.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif hasattr(model, 'classifier_head') and isinstance(model.classifier_head, nn.Module):\n",
    "            for p in model.classifier_head.parameters():\n",
    "                p.requires_grad = True\n",
    "        else:\n",
    "            # Fallback: find a module containing 'head' or 'classifier'\n",
    "            for name, module in model.named_modules():\n",
    "                if 'head' in name or 'classifier' in name:\n",
    "                    for p in module.parameters():\n",
    "                        p.requires_grad = True\n",
    "\n",
    "    def unfreeze_last_n_blocks(blocks, n):\n",
    "        if n > len(blocks):\n",
    "            n = len(blocks)\n",
    "        for block in blocks[-n:]:\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    def unfreeze_half_blocks(blocks):\n",
    "        n = len(blocks) // 2\n",
    "        unfreeze_last_n_blocks(blocks, n)\n",
    "\n",
    "    def unfreeze_all_blocks(blocks):\n",
    "        for block in blocks:\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    # Initialize the model with 5 input channels and no pretrained weights\n",
    "    if model_name == 'ViT':\n",
    "        model = timm.create_model('vit_base_patch16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'CaiT':\n",
    "        model = timm.create_model('cait_s24_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'DeiT':\n",
    "        model = timm.create_model('deit_base_patch16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'DeiT3':\n",
    "        model = timm.create_model('deit3_base_patch16_224',\n",
    "                                  pretrained=pretrained,\n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'Swin':\n",
    "        model = timm.create_model('swin_base_patch4_window7_224',\n",
    "                                  pretrained=pretrained,\n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob,\n",
    "                                  num_classes=num_classes)\n",
    "        ft_attr = 'layers'\n",
    "    elif model_name == 'Twins_SVT':\n",
    "        model = timm.create_model('twins_svt_base',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'stages' if hasattr(model, 'stages') else None\n",
    "    elif model_name == 'Twins_PCPVT':\n",
    "        model = timm.create_model('twins_pcpvt_base',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'stages' if hasattr(model, 'stages') else None\n",
    "    elif model_name == 'PiT':\n",
    "        model = timm.create_model('pit_b_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'MLP-Mixer':\n",
    "        model = timm.create_model('mixer_b16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not recognized.\")\n",
    "\n",
    "    # Freeze everything initially\n",
    "    freeze_all(model)\n",
    "    # Unfreeze the classification head\n",
    "    unfreeze_head(model)\n",
    "\n",
    "    if fine_tune_mode == \"classification_head\":\n",
    "        return model\n",
    "\n",
    "    # Otherwise, unfreeze more parameters according to the chosen mode\n",
    "    if fine_tune_mode == \"all_blocks\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_all_blocks(blocks)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            for n, p in model.named_parameters():\n",
    "                if not p.requires_grad:\n",
    "                    p.requires_grad = True\n",
    "    elif fine_tune_mode == \"last_n_blocks\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_last_n_blocks(blocks, last_n)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            all_params = list(model.named_parameters())\n",
    "            frozen = [(n, p) for (n, p) in all_params if not p.requires_grad]\n",
    "            if last_n > len(frozen):\n",
    "                last_n = len(frozen)\n",
    "            for (n, p) in frozen[-last_n:]:\n",
    "                p.requires_grad = True\n",
    "    elif fine_tune_mode == \"half\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_half_blocks(blocks)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            all_params = list(model.named_parameters())\n",
    "            frozen = [(n, p) for (n, p) in all_params if not p.requires_grad]\n",
    "            half_n = len(frozen) // 2\n",
    "            for (n, p) in frozen[-half_n:]:\n",
    "                p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(\"fine_tune_mode must be one of: 'classification_head', 'last_n_blocks', 'half', 'all_blocks'\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, val_loss, fold, model_name, checkpoints_dir=\"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Save the model checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        optimizer: The optimizer state.\n",
    "        epoch (int): Current epoch number.\n",
    "        val_loss (float): Validation loss.\n",
    "        fold (int): Current fold number.\n",
    "        model_name (str): Name of the model.\n",
    "        checkpoints_dir (str): Directory to save checkpoints.\n",
    "    \"\"\"\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    checkpoint_path = os.path.join(checkpoints_dir, f\"model_{model_name}_fold_{fold+1}_best.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_to_save.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "def train_one_fold(model, train_loader, val_loader, device, num_epochs=2, patience=1, fold=0, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Train the model for one fold.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        device: Device to train on.\n",
    "        num_epochs (int): Maximum number of epochs.\n",
    "        patience (int): Early stopping patience.\n",
    "        fold (int): Current fold number.\n",
    "        model_name (str): Name of the model.\n",
    "\n",
    "    Returns:\n",
    "        history (dict): Training and validation loss and accuracy history.\n",
    "        all_labels_np (np.ndarray): True labels.\n",
    "        all_preds_np (np.ndarray): Predicted labels.\n",
    "        all_preds_probs (np.ndarray): Predicted probabilities.\n",
    "        auc_roc (float): ROC AUC score.\n",
    "        f1 (float): F1 score.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)  # Reduced lr and wd\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # For storing metrics\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "\n",
    "        # Progress bar for training\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "        for X_batch, y_batch in train_iter:\n",
    "            X_batch = X_batch.to(device, non_blocking=True)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Check outputs for NaN or Inf\n",
    "            if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                print(\"Model outputs contain NaN or Inf.\")\n",
    "                raise ValueError(\"Invalid model outputs.\")\n",
    "\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Check loss for NaN or Inf\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"Loss is NaN or Inf.\")\n",
    "                raise ValueError(\"Invalid loss.\")\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Check gradients for NaN or Inf\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                        print(f\"Gradient issue in parameter: {name}\")\n",
    "                        raise ValueError(\"Invalid gradients.\")\n",
    "\n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_train += (preds == y_batch).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct_train / len(train_loader.dataset)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        preds_list = []\n",
    "        labels_list = []\n",
    "        probs_list = []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = X_val.to(device, non_blocking=True)\n",
    "                y_val = y_val.to(device, non_blocking=True)\n",
    "                outputs = model(X_val)\n",
    "                \n",
    "                # Check outputs for NaN or Inf\n",
    "                if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                    print(\"Validation model outputs contain NaN or Inf.\")\n",
    "                    raise ValueError(\"Invalid validation model outputs.\")\n",
    "\n",
    "                loss = criterion(outputs, y_val)\n",
    "                \n",
    "                # Check loss for NaN or Inf\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(\"Validation loss is NaN or Inf.\")\n",
    "                    raise ValueError(\"Invalid validation loss.\")\n",
    "\n",
    "                val_loss += loss.item() * X_val.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_val += (preds == y_val).sum().item()\n",
    "\n",
    "                preds_list.extend(preds.cpu().numpy())\n",
    "                labels_list.extend(y_val.cpu().numpy())\n",
    "\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                probs_list.extend(probs.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct_val / len(val_loader.dataset)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        all_preds.extend(preds_list)\n",
    "        all_labels.extend(labels_list)\n",
    "        all_probs.extend(probs_list)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "        # Checkpoint if best\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            save_checkpoint(model, optimizer, epoch, val_loss, fold, model_name)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # After training, compute metrics\n",
    "    # Assuming multi-class classification\n",
    "    num_classes = model.module.head.out_features if hasattr(model, 'module') else model.head.out_features\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    all_preds_np = np.array(all_preds)\n",
    "    all_probs_np = np.array(all_probs)\n",
    "\n",
    "    # Binarize the labels for ROC AUC\n",
    "    all_labels_binarized = label_binarize(all_labels_np, classes=np.arange(num_classes))\n",
    "    if all_labels_binarized.shape[1] == 1:\n",
    "        # Handle binary classification case\n",
    "        all_labels_binarized = np.hstack((1 - all_labels_binarized, all_labels_binarized))\n",
    "\n",
    "    # Compute ROC AUC\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(all_labels_binarized, all_probs_np, average='macro', multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc_roc = float('nan')  # Handle cases where ROC AUC cannot be computed\n",
    "\n",
    "    # Compute F1 Score\n",
    "    f1 = f1_score(all_labels_np, all_preds_np, average='macro')\n",
    "\n",
    "    return history, all_labels_np, all_preds_np, all_probs_np, auc_roc, f1\n",
    "\n",
    "def compute_channel_stats(X_tensor):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        X_tensor (torch.Tensor): Input tensor of shape (N, C, H, W).\n",
    "\n",
    "    Returns:\n",
    "        means (torch.Tensor): Mean for each channel.\n",
    "        stds (torch.Tensor): Standard deviation for each channel.\n",
    "    \"\"\"\n",
    "    # Compute per-channel mean and std\n",
    "    means = X_tensor.mean(dim=(0, 2, 3))\n",
    "    stds = X_tensor.std(dim=(0, 2, 3))\n",
    "    return means, stds\n",
    "\n",
    "class FITSDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the FITSDataset.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input images tensor of shape (N, C, H, W).\n",
    "            y (torch.Tensor): Labels tensor of shape (N,).\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]  # (5, H, W) tensor\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.y[idx]\n",
    "        return img, label\n",
    "\n",
    "def plot_combined_metrics(fpr, tpr, roc_auc, cm, classes, model_name, fold, model_color, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot and save the ROC curve on the left and the Confusion Matrix on the right.\n",
    "    Also displays the figure inline.\n",
    "    \n",
    "    Args:\n",
    "        fpr (dict): False positive rates for each class.\n",
    "        tpr (dict): True positive rates for each class.\n",
    "        roc_auc (dict): AUC scores for each class.\n",
    "        cm (np.ndarray): Confusion matrix.\n",
    "        classes (list or np.ndarray): List of class labels.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from itertools import cycle\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # === Left Subplot: ROC Curve ===\n",
    "    ax1 = axes[0]\n",
    "    if len(classes) == 2:\n",
    "        # Binary classification: plot ROC for the positive class only\n",
    "        pos_class = classes[1]  # Assuming the second class is the positive class\n",
    "        ax1.plot(fpr[1], tpr[1], color=model_color,\n",
    "                 lw=2, label=f'ROC curve (AUC = {roc_auc[1]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curve for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    else:\n",
    "        # Multi-class classification: plot ROC for each class using model_color and different line styles\n",
    "        line_styles = cycle(['-', '--', '-.', ':', '-', '--', '-.', ':', '-'])\n",
    "        for i, ls in zip(range(len(classes)), line_styles):\n",
    "            ax1.plot(fpr[i], tpr[i], color=model_color, linestyle=ls, lw=2,\n",
    "                     label=f'ROC curve of class {classes[i]} (AUC = {roc_auc[i]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curves for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    \n",
    "    # === Right Subplot: Confusion Matrix ===\n",
    "    ax2 = axes[1]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes, ax=ax2)\n",
    "    ax2.set_ylabel('Actual')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_title(f'Confusion Matrix for {model_name} Fold {fold+1}', color='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'combined_metrics_{model_name}_fold_{fold+1}.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Combined metrics saved at {save_path}\")\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(fig)\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "def plot_learning_curves(history, model_name, fold, model_color, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot and save the learning curves. Also display them inline.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Dictionary containing training and validation loss and accuracy.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'o-', color='grey', label='Training loss')\n",
    "    plt.plot(epochs, history['val_loss'], 's-', color=model_color, label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss for {model_name} Fold {fold+1}', color='black')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'o-', color='grey', label='Training accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 's-', color=model_color, label='Validation accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy for {model_name} Fold {fold+1}', color='black')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'learning_curves_{model_name}_fold_{fold+1}.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Learning curves saved at {save_path}\")\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "def plot_aggregated_roc_curves(model_roc_data, num_classes, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot aggregated ROC curves for all models.\n",
    "\n",
    "    Args:\n",
    "        model_roc_data (dict): Dictionary where keys are model names and values are lists of (fpr, tpr) tuples per fold.\n",
    "        num_classes (int): Number of classes.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    colors = {\n",
    "        'ViT': 'crimson',\n",
    "        'MLP-Mixer': 'tomato',\n",
    "        'CvT': 'darkred',\n",
    "        'Swin': 'indigo',\n",
    "        'CaiT': 'royalblue',\n",
    "        'DeiT': 'cadetblue',\n",
    "        'DeiT3': 'dodgerblue',\n",
    "        'Twins_SVT': 'lightgreen',\n",
    "        'Twins_PCPVT': 'mediumseagreen',\n",
    "        'PiT': 'dimgrey',\n",
    "        'Ensemble': 'darkgoldenrod',\n",
    "        'Random': 'black'\n",
    "    }\n",
    "\n",
    "    for model_name, roc_list in model_roc_data.items():\n",
    "        if not roc_list:\n",
    "            continue  # Skip models with no ROC data\n",
    "        # Aggregate ROC by averaging TPRs at common FPR points\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        tprs = []\n",
    "        for fpr, tpr in roc_list:\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0  # Ensure TPR starts at 0\n",
    "            tprs.append(interp_tpr)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0  # Ensure TPR ends at 1\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        plt.plot(mean_fpr, mean_tpr, color=colors.get(model_name, 'black'),\n",
    "                 lw=2, label=f'{model_name} (AUC = {mean_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Aggregated ROC Curves for All Models')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'aggregated_roc_curves.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Aggregated ROC curves saved at {save_path}\")\n",
    "\n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "\n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "def plot_combined_metrics(fpr, tpr, roc_auc, cm, classes, model_name, fold, model_color, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot and save the ROC curve on the left and the Confusion Matrix on the right.\n",
    "    Also displays the figure inline.\n",
    "    \n",
    "    Args:\n",
    "        fpr (dict): False positive rates for each class.\n",
    "        tpr (dict): True positive rates for each class.\n",
    "        roc_auc (dict): AUC scores for each class.\n",
    "        cm (np.ndarray): Confusion matrix.\n",
    "        classes (list or np.ndarray): List of class labels.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from itertools import cycle\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # === Left Subplot: ROC Curve ===\n",
    "    ax1 = axes[0]\n",
    "    if len(classes) == 2:\n",
    "        # Binary classification: plot ROC for the positive class only\n",
    "        pos_class = classes[1]  # Assuming the second class is the positive class\n",
    "        ax1.plot(fpr[1], tpr[1], color=model_color,\n",
    "                 lw=2, label=f'ROC curve (AUC = {roc_auc[1]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curve for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    else:\n",
    "        # Multi-class classification: plot ROC for each class using model_color and different line styles\n",
    "        line_styles = cycle(['-', '--', '-.', ':', '-', '--', '-.', ':', '-'])\n",
    "        for i, ls in zip(range(len(classes)), line_styles):\n",
    "            ax1.plot(fpr[i], tpr[i], color=model_color, linestyle=ls, lw=2,\n",
    "                     label=f'ROC curve of class {classes[i]} (AUC = {roc_auc[i]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curves for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    \n",
    "    # === Right Subplot: Confusion Matrix ===\n",
    "    ax2 = axes[1]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes, ax=ax2)\n",
    "    ax2.set_ylabel('Actual')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_title(f'Confusion Matrix for {model_name} Fold {fold+1}', color='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'combined_metrics_{model_name}_fold_{fold+1}.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Combined metrics saved at {save_path}\")\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(fig)\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "def plot_learning_curves(history, model_name, fold, model_color, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot and save the learning curves. Also display them inline.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Dictionary containing training and validation loss and accuracy.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'o-', color='grey', label='Training loss')\n",
    "    plt.plot(epochs, history['val_loss'], 's-', color=model_color, label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss for {model_name} Fold {fold+1}', color=model_color)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'o-', color='grey', label='Training accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 's-', color=model_color, label='Validation accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy for {model_name} Fold {fold+1}', color=model_color)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'learning_curves_{model_name}_fold_{fold+1}.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Learning curves saved at {save_path}\")\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "def plot_aggregated_roc_curves(model_roc_data, num_classes, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot aggregated ROC curves for all models.\n",
    "\n",
    "    Args:\n",
    "        model_roc_data (dict): Dictionary where keys are model names and values are lists of (fpr, tpr) tuples per fold.\n",
    "        num_classes (int): Number of classes.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    colors = {\n",
    "        'ViT': 'crimson',\n",
    "        'MLP-Mixer': 'tomato',\n",
    "        'CvT': 'darkred',\n",
    "        'Swin': 'indigo',\n",
    "        'CaiT': 'royalblue',\n",
    "        'DeiT': 'cadetblue',\n",
    "        'DeiT3': 'dodgerblue',\n",
    "        'Twins_SVT': 'lightgreen',\n",
    "        'Twins_PCPVT': 'mediumseagreen',\n",
    "        'PiT': 'dimgrey',\n",
    "        'Ensemble': 'darkgoldenrod',\n",
    "        'Random': 'black'\n",
    "    }\n",
    "\n",
    "    for model_name, roc_list in model_roc_data.items():\n",
    "        if not roc_list:\n",
    "            continue  # Skip models with no ROC data\n",
    "        # Aggregate ROC by averaging TPRs at common FPR points\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        tprs = []\n",
    "        for fpr, tpr in roc_list:\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0  # Ensure TPR starts at 0\n",
    "            tprs.append(interp_tpr)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0  # Ensure TPR ends at 1\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        plt.plot(mean_fpr, mean_tpr, color=colors.get(model_name, 'black'),\n",
    "                 lw=2, label=f'{model_name} (AUC = {mean_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Aggregated ROC Curves for All Models')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'aggregated_roc_curves.png')\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Aggregated ROC curves saved at {save_path}\")\n",
    "\n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "\n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_dir = \"/home/parlange/datasets/mini_sample/images\"\n",
    "    metadata_file = \"/home/parlange/datasets/mini_sample/metadata_catalog.fits\"\n",
    "\n",
    "    bands = ['g', 'r', 'i', 'z', 'y']\n",
    "    image_files = {\n",
    "        'g': 'image_catalog_g.fits',\n",
    "        'r': 'image_catalog_r.fits',\n",
    "        'i': 'image_catalog_i.fits',\n",
    "        'z': 'image_catalog_z.fits',\n",
    "        'y': 'image_catalog_y.fits'\n",
    "    }\n",
    "\n",
    "    band_data = []\n",
    "    shapes = []\n",
    "    for b in bands:\n",
    "        file_path = os.path.join(images_dir, image_files[b])\n",
    "        with fits.open(file_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "            print(f\"Shape for {b} band: {data.shape}\")\n",
    "            # Replace NaN and Inf with zeros\n",
    "            data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            band_data.append(data)\n",
    "            shapes.append(data.shape)\n",
    "\n",
    "    unique_shapes = set(shapes)\n",
    "    if len(unique_shapes) != 1:\n",
    "        raise ValueError(f\"Inconsistent shapes among bands: {unique_shapes}\")\n",
    "\n",
    "    X = np.stack(band_data, axis=1)\n",
    "    print(\"Final X shape:\", X.shape)\n",
    "\n",
    "    with fits.open(metadata_file) as hdul:\n",
    "        meta_data = hdul[1].data\n",
    "        y = np.array(meta_data['label'])\n",
    "        print(\"y shape:\", y.shape)\n",
    "\n",
    "    y = y.astype(np.int64)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()   # (N, 5, H, W)\n",
    "    y_tensor = torch.from_numpy(y).long()    # (N,)\n",
    "\n",
    "    # Check for remaining NaNs or Infs\n",
    "    if torch.isnan(X_tensor).any():\n",
    "        print(\"X_tensor contains NaN values. Replacing with 0.\")\n",
    "        X_tensor = torch.nan_to_num(X_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if torch.isinf(X_tensor).any():\n",
    "        print(\"X_tensor contains Inf values. Replacing with 0.\")\n",
    "        X_tensor = torch.nan_to_num(X_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Compute channel statistics\n",
    "    means, stds = compute_channel_stats(X_tensor)\n",
    "    print(\"Per-channel means:\", means)\n",
    "    print(\"Per-channel stds:\", stds)\n",
    "\n",
    "    # Check for NaN or Inf in means and stds\n",
    "    if torch.isnan(means).any() or torch.isnan(stds).any():\n",
    "        print(\"Computed means or stds contain NaN. Replacing with 0.5 and 0.5 respectively.\")\n",
    "        means = torch.where(torch.isnan(means), torch.tensor(0.5), means)\n",
    "        stds = torch.where(torch.isnan(stds), torch.tensor(0.5), stds)\n",
    "    if torch.isinf(means).any() or torch.isinf(stds).any():\n",
    "        print(\"Computed means or stds contain Inf. Replacing with 1.0 and 1.0 respectively.\")\n",
    "        means = torch.where(torch.isinf(means), torch.tensor(1.0), means)\n",
    "        stds = torch.where(torch.isinf(stds), torch.tensor(1.0), stds)\n",
    "\n",
    "    # Define training and validation transforms with normalization\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        RandomApply([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=30),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.2)),\n",
    "            transforms.RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "        ], p=0.5),\n",
    "        transforms.Normalize(mean=means.tolist(),\n",
    "                             std=stds.tolist())\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=means.tolist(),\n",
    "                             std=stds.tolist())\n",
    "    ])\n",
    "\n",
    "    dataset = FITSDataset(X_tensor, y_tensor)\n",
    "    N = len(dataset)\n",
    "    num_classes = len(torch.unique(y_tensor))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Number of GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "    # List of models to train\n",
    "    model_names = ['ViT', 'CaiT', 'DeiT', 'DeiT3', 'Swin', \n",
    "                  'Twins_SVT', 'Twins_PCPVT', 'PiT', 'MLP-Mixer']\n",
    "\n",
    "    # Define per-model fine-tuning configurations with 'last_n_blocks' mode and exact last_n values\n",
    "    model_config = {\n",
    "        'ViT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},          # 12 blocks / 2 = 6\n",
    "        'CaiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 12},        # 24 blocks / 2 = 12\n",
    "        'DeiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},         # 12 blocks / 2 = 6\n",
    "        'DeiT3': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},        # 12 blocks / 2 = 6\n",
    "        'Swin': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},         # 12 blocks / 2 = 6\n",
    "        'Twins_SVT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},    # 12 blocks / 2 = 6\n",
    "        'Twins_PCPVT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 2},  # 4 blocks / 2 = 2\n",
    "        'PiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},          # 12 blocks / 2 = 6\n",
    "        'MLP-Mixer': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},    # 12 blocks / 2 = 6\n",
    "    }\n",
    "\n",
    "    k = 5\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # To store overall results\n",
    "    model_metrics = {model: {'auc_roc': [], 'f1': []} for model in model_names}\n",
    "    # To store ROC data for aggregated plotting\n",
    "    model_roc_data = {model: [] for model in model_names}\n",
    "\n",
    "    # Define your colors dictionary\n",
    "    colors = {\n",
    "        'ViT': 'crimson',\n",
    "        'MLP-Mixer': 'tomato',\n",
    "        'CvT': 'darkred',\n",
    "        'Swin': 'indigo',\n",
    "        'CaiT': 'royalblue',\n",
    "        'DeiT': 'cadetblue',\n",
    "        'DeiT3': 'dodgerblue',\n",
    "        'Twins_SVT': 'lightgreen',\n",
    "        'Twins_PCPVT': 'mediumseagreen',\n",
    "        'PiT': 'dimgrey',\n",
    "        'Ensemble': 'darkgoldenrod',\n",
    "        'Random': 'black'\n",
    "    }\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n==== Training Model: {model_name} ====\\n\")\n",
    "        fold_results = []\n",
    "        # Iterate through each fold\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(N), y_tensor.cpu().numpy())):\n",
    "            print(f\"\\n=== Fold {fold+1}/{k} for model {model_name} ===\")\n",
    "            print(f\"Train indices length: {len(train_idx)}, Val indices length: {len(val_idx)}\")\n",
    "\n",
    "            train_subset = Subset(FITSDataset(X_tensor[train_idx], y_tensor[train_idx], transform=train_transform), range(len(train_idx)))\n",
    "            val_subset = Subset(FITSDataset(X_tensor[val_idx], y_tensor[val_idx], transform=val_transform), range(len(val_idx)))\n",
    "\n",
    "            pin_memory = torch.cuda.is_available()\n",
    "            train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4, pin_memory=pin_memory)\n",
    "            val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4, pin_memory=pin_memory)\n",
    "\n",
    "            # Get model configuration\n",
    "            config = model_config.get(model_name, {'fine_tune_mode': 'classification_head', 'last_n': 6})\n",
    "            fine_tune_mode = config['fine_tune_mode']\n",
    "            last_n = config['last_n'] if config['last_n'] is not None else 6  # Default to 6 if not set\n",
    "\n",
    "            # Print the fine-tuning mode and last_n if applicable\n",
    "            if fine_tune_mode == 'last_n_blocks':\n",
    "                print(f\"Fine-tuning mode: {fine_tune_mode} with last_n={last_n}\")\n",
    "            else:\n",
    "                print(f\"Fine-tuning mode: {fine_tune_mode}\")\n",
    "\n",
    "            model = initialize_model(model_name, num_classes, pretrained=False, fine_tune_mode=fine_tune_mode, last_n=last_n)\n",
    "\n",
    "            model = model.to(device)\n",
    "            if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "                model = nn.DataParallel(model)\n",
    "                print(\"Model wrapped in DataParallel.\")\n",
    "\n",
    "            try:\n",
    "                history, all_labels_np, all_preds_np, all_preds_probs, auc_roc, f1 = train_one_fold(\n",
    "                    model, train_loader, val_loader, device, num_epochs=2, patience=1, fold=fold, model_name=model_name\n",
    "                )\n",
    "                fold_results.append((auc_roc, f1))\n",
    "                model_metrics[model_name]['auc_roc'].append(auc_roc)\n",
    "                model_metrics[model_name]['f1'].append(f1)\n",
    "\n",
    "                # Retrieve the model's color from the colors dictionary\n",
    "                model_color = colors.get(model_name, 'black')  # Default to 'black' if not found\n",
    "\n",
    "                # Plot learning curves\n",
    "                plot_learning_curves(history, model_name, fold, model_color=model_color)\n",
    "\n",
    "                # Compute confusion matrix\n",
    "                cm = confusion_matrix(all_labels_np, all_preds_np)\n",
    "                # Removed the standalone confusion matrix plot\n",
    "                # plot_confusion_matrix(cm, classes=np.arange(num_classes), model_name=model_name, fold=fold, model_color=model_color)\n",
    "\n",
    "                # Compute ROC curves\n",
    "                # Binarize the labels for ROC\n",
    "                all_labels_binarized = label_binarize(all_labels_np, classes=np.arange(num_classes))\n",
    "                if all_labels_binarized.shape[1] == 1:\n",
    "                    # Handle binary classification case\n",
    "                    all_labels_binarized = np.hstack((1 - all_labels_binarized, all_labels_binarized))\n",
    "\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc_dict = dict()\n",
    "                for i in range(num_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(all_labels_binarized[:, i], all_preds_probs[:, i])\n",
    "                    roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "                # Store ROC data for aggregated plotting\n",
    "                model_roc_data[model_name].append((fpr, tpr))\n",
    "\n",
    "                # Plot combined metrics (ROC and Confusion Matrix)\n",
    "                plot_combined_metrics(fpr, tpr, roc_auc_dict, cm, classes=np.arange(num_classes), \n",
    "                                      model_name=model_name, fold=fold, model_color=model_color)\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Training stopped due to error: {e}\")\n",
    "                break  # Optionally, continue with next fold or model\n",
    "\n",
    "        if fold_results:\n",
    "            avg_auc = np.mean([res[0] for res in fold_results])\n",
    "            avg_f1 = np.mean([res[1] for res in fold_results])\n",
    "            print(f\"\\nResults for {model_name}: Average AUC-ROC: {avg_auc:.4f}, Average F1 Score: {avg_f1:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\nNo results for {model_name} due to training issues.\")\n",
    "\n",
    "    # After all models have been trained, create and display the rankings\n",
    "    ranking_auc = sorted(model_metrics.items(), key=lambda x: np.nanmean(x[1]['auc_roc']), reverse=True)\n",
    "    ranking_f1 = sorted(model_metrics.items(), key=lambda x: np.nanmean(x[1]['f1']), reverse=True)\n",
    "\n",
    "    # Create DataFrames for rankings\n",
    "    ranking_auc_df = pd.DataFrame(ranking_auc, columns=['Model', 'Metrics'])\n",
    "    ranking_auc_df['Average AUC-ROC'] = ranking_auc_df['Metrics'].apply(lambda x: np.nanmean(x['auc_roc']))\n",
    "    ranking_auc_df = ranking_auc_df.drop('Metrics', axis=1).sort_values(by='Average AUC-ROC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    ranking_f1_df = pd.DataFrame(ranking_f1, columns=['Model', 'Metrics'])\n",
    "    ranking_f1_df['Average F1 Score'] = ranking_f1_df['Metrics'].apply(lambda x: np.nanmean(x['f1']))\n",
    "    ranking_f1_df = ranking_f1_df.drop('Metrics', axis=1).sort_values(by='Average F1 Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Display the rankings in the notebook\n",
    "    print(\"\\n==== Model Ranking Based on AUC-ROC ====\")\n",
    "    display(ranking_auc_df)\n",
    "\n",
    "    print(\"\\n==== Model Ranking Based on F1 Score ====\")\n",
    "    display(ranking_f1_df)\n",
    "\n",
    "    # Plot aggregated ROC curves for all models\n",
    "    print(\"\\n==== Plotting Aggregated ROC Curves for All Models ====\")\n",
    "    plot_aggregated_roc_curves(model_roc_data, num_classes, save_dir=\"plots\")\n",
    "\n",
    "    # Optionally, save the ranking results to a file\n",
    "    with open(\"model_ranking.txt\", \"w\") as f:\n",
    "        f.write(\"Model Ranking Based on AUC-ROC:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(ranking_auc, start=1):\n",
    "            f.write(f\"{rank}. {model} - Average AUC-ROC: {np.nanmean(metrics['auc_roc']):.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nModel Ranking Based on F1 Score:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(ranking_f1, start=1):\n",
    "            f.write(f\"{rank}. {model} - Average F1 Score: {np.nanmean(metrics['f1']):.4f}\\n\")\n",
    "    \n",
    "    print(\"\\nModel rankings have been saved to 'model_ranking.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4bfc7-b010-4505-b4b3-bee8c6c5d7ba",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7864b1d-0047-429c-b390-f2a4d172efd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape for g band: (20000, 61, 61)\n",
      "Shape for r band: (20000, 61, 61)\n",
      "Shape for i band: (20000, 61, 61)\n",
      "Shape for z band: (20000, 61, 61)\n",
      "Shape for y band: (20000, 61, 61)\n",
      "Final X shape: (20000, 5, 61, 61)\n",
      "y shape: (20000,)\n",
      "Per-channel means: tensor([0.2430, 0.3049, 0.5290, 0.6589, 0.7684])\n",
      "Per-channel stds: tensor([3.4988, 3.4331, 6.2919, 7.4187, 7.9995])\n",
      "Using device: cuda\n",
      "Number of GPUs: 2\n",
      "\n",
      "==== Training Model: ViT ====\n",
      "\n",
      "\n",
      "=== Fold 1/5 for model ViT ===\n",
      "Train indices length: 16000, Val indices length: 4000\n",
      "Fine-tuning mode: last_n_blocks with last_n=6\n",
      "Model wrapped in DataParallel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Train Loss: 0.2032, Train Acc: 91.76% | Val Loss: 0.0837, Val Acc: 97.15% | Epoch Time: 105.58s | Val Time: 13.24s\n",
      "Checkpoint saved at checkpoints/model_ViT_fold_1_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2:  87%|      | 434/500 [01:32<00:14,  4.64it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time  # Importing time for timers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import timm\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomApply\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "import pandas as pd  # For DataFrame handling\n",
    "from IPython.display import display  # For displaying DataFrames in Jupyter\n",
    "\n",
    "# Suppress potential warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def initialize_model(model_name, num_classes, pretrained=False, stochastic_depth_prob=0.1, \n",
    "                    fine_tune_mode=\"classification_head\", last_n=6):\n",
    "    \"\"\"\n",
    "    Initialize a model from the given model_name without ImageNet pretraining and\n",
    "    allow for a custom number of input channels (5).\n",
    "\n",
    "    Args:\n",
    "        model_name (str): One of [ViT, CaiT, DeiT, DeiT3, Swin, Twins_SVT, Twins_PCPVT, PiT, MLP-Mixer].\n",
    "        num_classes (int): Number of output classes.\n",
    "        pretrained (bool): Whether to load a pretrained model. Here we set it to False.\n",
    "        stochastic_depth_prob (float): The stochastic depth probability for supported models.\n",
    "        fine_tune_mode (str): 'classification_head', 'last_n_blocks', 'half', or 'all_blocks'.\n",
    "        last_n (int): Number of blocks/layers to unfreeze if using 'last_n_blocks'.\n",
    "\n",
    "    Returns:\n",
    "        model: The initialized and partially unfrozen model.\n",
    "    \"\"\"\n",
    "    def freeze_all(model):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_head(model):\n",
    "        if hasattr(model, 'head') and isinstance(model.head, nn.Module):\n",
    "            for p in model.head.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif hasattr(model, 'classifier') and isinstance(model.classifier, nn.Module):\n",
    "            for p in model.classifier.parameters():\n",
    "                p.requires_grad = True\n",
    "        elif hasattr(model, 'classifier_head') and isinstance(model.classifier_head, nn.Module):\n",
    "            for p in model.classifier_head.parameters():\n",
    "                p.requires_grad = True\n",
    "        else:\n",
    "            # Fallback: find a module containing 'head' or 'classifier'\n",
    "            for name, module in model.named_modules():\n",
    "                if 'head' in name or 'classifier' in name:\n",
    "                    for p in module.parameters():\n",
    "                        p.requires_grad = True\n",
    "\n",
    "    def unfreeze_last_n_blocks(blocks, n):\n",
    "        if n > len(blocks):\n",
    "            n = len(blocks)\n",
    "        for block in blocks[-n:]:\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    def unfreeze_half_blocks(blocks):\n",
    "        n = len(blocks) // 2\n",
    "        unfreeze_last_n_blocks(blocks, n)\n",
    "\n",
    "    def unfreeze_all_blocks(blocks):\n",
    "        for block in blocks:\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    # Initialize the model with 5 input channels and no pretrained weights\n",
    "    if model_name == 'ViT':\n",
    "        model = timm.create_model('vit_base_patch16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'CaiT':\n",
    "        model = timm.create_model('cait_s24_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'DeiT':\n",
    "        model = timm.create_model('deit_base_patch16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'DeiT3':\n",
    "        model = timm.create_model('deit3_base_patch16_224',\n",
    "                                  pretrained=pretrained,\n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'Swin':\n",
    "        model = timm.create_model('swin_base_patch4_window7_224',\n",
    "                                  pretrained=pretrained,\n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob,\n",
    "                                  num_classes=num_classes)\n",
    "        ft_attr = 'layers'\n",
    "    elif model_name == 'Twins_SVT':\n",
    "        model = timm.create_model('twins_svt_base',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'stages' if hasattr(model, 'stages') else None\n",
    "    elif model_name == 'Twins_PCPVT':\n",
    "        model = timm.create_model('twins_pcpvt_base',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'stages' if hasattr(model, 'stages') else None\n",
    "    elif model_name == 'PiT':\n",
    "        model = timm.create_model('pit_b_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    elif model_name == 'MLP-Mixer':\n",
    "        model = timm.create_model('mixer_b16_224',\n",
    "                                  pretrained=pretrained, \n",
    "                                  in_chans=5,\n",
    "                                  drop_path_rate=stochastic_depth_prob)\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "        ft_attr = 'blocks'\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not recognized.\")\n",
    "\n",
    "    # Freeze everything initially\n",
    "    freeze_all(model)\n",
    "    # Unfreeze the classification head\n",
    "    unfreeze_head(model)\n",
    "\n",
    "    if fine_tune_mode == \"classification_head\":\n",
    "        return model\n",
    "\n",
    "    # Otherwise, unfreeze more parameters according to the chosen mode\n",
    "    if fine_tune_mode == \"all_blocks\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_all_blocks(blocks)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            for n, p in model.named_parameters():\n",
    "                if not p.requires_grad:\n",
    "                    p.requires_grad = True\n",
    "    elif fine_tune_mode == \"last_n_blocks\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_last_n_blocks(blocks, last_n)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            all_params = list(model.named_parameters())\n",
    "            frozen = [(n, p) for (n, p) in all_params if not p.requires_grad]\n",
    "            if last_n > len(frozen):\n",
    "                last_n = len(frozen)\n",
    "            for (n, p) in frozen[-last_n:]:\n",
    "                p.requires_grad = True\n",
    "    elif fine_tune_mode == \"half\":\n",
    "        if ft_attr and hasattr(model, ft_attr):\n",
    "            blocks = getattr(model, ft_attr)\n",
    "            unfreeze_half_blocks(blocks)\n",
    "        else:\n",
    "            # Fallback: parameter-based unfreezing\n",
    "            all_params = list(model.named_parameters())\n",
    "            frozen = [(n, p) for (n, p) in all_params if not p.requires_grad]\n",
    "            half_n = len(frozen) // 2\n",
    "            for (n, p) in frozen[-half_n:]:\n",
    "                p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(\"fine_tune_mode must be one of: 'classification_head', 'last_n_blocks', 'half', 'all_blocks'\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, val_loss, fold, model_name, checkpoints_dir=\"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Save the model checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        optimizer: The optimizer state.\n",
    "        epoch (int): Current epoch number.\n",
    "        val_loss (float): Validation loss.\n",
    "        fold (int): Current fold number.\n",
    "        model_name (str): Name of the model.\n",
    "        checkpoints_dir (str): Directory to save checkpoints.\n",
    "    \"\"\"\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    checkpoint_path = os.path.join(checkpoints_dir, f\"model_{model_name}_fold_{fold+1}_best.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_to_save.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "\n",
    "def train_one_fold(model, train_loader, val_loader, device, num_epochs=2, patience=1, fold=0, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Train the model for one fold.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        device: Device to train on.\n",
    "        num_epochs (int): Maximum number of epochs.\n",
    "        patience (int): Early stopping patience.\n",
    "        fold (int): Current fold number.\n",
    "        model_name (str): Name of the model.\n",
    "\n",
    "    Returns:\n",
    "        history (dict): Training and validation loss and accuracy history.\n",
    "        all_labels_np (np.ndarray): True labels.\n",
    "        all_preds_np (np.ndarray): Predicted labels.\n",
    "        all_preds_probs (np.ndarray): Predicted probabilities.\n",
    "        auc_roc (float): ROC AUC score.\n",
    "        f1 (float): F1 score.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)  # Reduced lr and wd\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # For storing metrics\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    total_start_time = time.perf_counter()  # Start timer for the entire fold\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.perf_counter()  # Start timer for the epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "\n",
    "        # Progress bar for training\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for X_batch, y_batch in train_iter:\n",
    "            X_batch = X_batch.to(device, non_blocking=True)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Check outputs for NaN or Inf\n",
    "            if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                print(\"Model outputs contain NaN or Inf.\")\n",
    "                raise ValueError(\"Invalid model outputs.\")\n",
    "\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Check loss for NaN or Inf\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"Loss is NaN or Inf.\")\n",
    "                raise ValueError(\"Invalid loss.\")\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Check gradients for NaN or Inf\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                        print(f\"Gradient issue in parameter: {name}\")\n",
    "                        raise ValueError(\"Invalid gradients.\")\n",
    "\n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_train += (preds == y_batch).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct_train / len(train_loader.dataset)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        # Training time for the epoch\n",
    "        epoch_end_time = time.perf_counter()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "        # Validation\n",
    "        val_start_time = time.perf_counter()  # Start timer for validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        preds_list = []\n",
    "        labels_list = []\n",
    "        probs_list = []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = X_val.to(device, non_blocking=True)\n",
    "                y_val = y_val.to(device, non_blocking=True)\n",
    "                outputs = model(X_val)\n",
    "                \n",
    "                # Check outputs for NaN or Inf\n",
    "                if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "                    print(\"Validation model outputs contain NaN or Inf.\")\n",
    "                    raise ValueError(\"Invalid validation model outputs.\")\n",
    "\n",
    "                loss = criterion(outputs, y_val)\n",
    "                \n",
    "                # Check loss for NaN or Inf\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(\"Validation loss is NaN or Inf.\")\n",
    "                    raise ValueError(\"Invalid validation loss.\")\n",
    "\n",
    "                val_loss += loss.item() * X_val.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct_val += (preds == y_val).sum().item()\n",
    "\n",
    "                preds_list.extend(preds.cpu().numpy())\n",
    "                labels_list.extend(y_val.cpu().numpy())\n",
    "\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                probs_list.extend(probs.cpu().numpy())\n",
    "\n",
    "        val_end_time = time.perf_counter()\n",
    "        val_duration = val_end_time - val_start_time\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct_val / len(val_loader.dataset)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        all_preds.extend(preds_list)\n",
    "        all_labels.extend(labels_list)\n",
    "        all_probs.extend(probs_list)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}% | \"\n",
    "              f\"Epoch Time: {epoch_duration:.2f}s | Val Time: {val_duration:.2f}s\")\n",
    "\n",
    "        # Checkpoint if best\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            save_checkpoint(model, optimizer, epoch, val_loss, fold, model_name)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    total_end_time = time.perf_counter()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "    print(f\"Total time for Fold {fold+1}: {total_duration:.2f}s\")\n",
    "\n",
    "    # After training, compute metrics\n",
    "    # Assuming multi-class classification\n",
    "    num_classes = model.module.head.out_features if hasattr(model, 'module') else model.head.out_features\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    all_preds_np = np.array(all_preds)\n",
    "    all_probs_np = np.array(all_probs)\n",
    "\n",
    "    # Binarize the labels for ROC AUC\n",
    "    all_labels_binarized = label_binarize(all_labels_np, classes=np.arange(num_classes))\n",
    "    if all_labels_binarized.shape[1] == 1:\n",
    "        # Handle binary classification case\n",
    "        all_labels_binarized = np.hstack((1 - all_labels_binarized, all_labels_binarized))\n",
    "\n",
    "    # Compute ROC AUC\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(all_labels_binarized, all_probs_np, average='macro', multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc_roc = float('nan')  # Handle cases where ROC AUC cannot be computed\n",
    "\n",
    "    # Compute F1 Score\n",
    "    f1 = f1_score(all_labels_np, all_preds_np, average='macro')\n",
    "\n",
    "    return history, all_labels_np, all_preds_np, all_probs_np, auc_roc, f1\n",
    "\n",
    "\n",
    "def compute_channel_stats(X_tensor):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        X_tensor (torch.Tensor): Input tensor of shape (N, C, H, W).\n",
    "\n",
    "    Returns:\n",
    "        means (torch.Tensor): Mean for each channel.\n",
    "        stds (torch.Tensor): Standard deviation for each channel.\n",
    "    \"\"\"\n",
    "    # Compute per-channel mean and std\n",
    "    means = X_tensor.mean(dim=(0, 2, 3))\n",
    "    stds = X_tensor.std(dim=(0, 2, 3))\n",
    "    return means, stds\n",
    "\n",
    "\n",
    "class FITSDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the FITSDataset.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input images tensor of shape (N, C, H, W).\n",
    "            y (torch.Tensor): Labels tensor of shape (N,).\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]  # (5, H, W) tensor\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.y[idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def plot_combined_metrics(fpr, tpr, roc_auc, cm, classes, model_name, fold, model_color):\n",
    "    \"\"\"\n",
    "    Plot the ROC curve on the left and the Confusion Matrix on the right.\n",
    "    Only displays the figure inline without saving.\n",
    "\n",
    "    Args:\n",
    "        fpr (dict): False positive rates for each class.\n",
    "        tpr (dict): True positive rates for each class.\n",
    "        roc_auc (dict): AUC scores for each class.\n",
    "        cm (np.ndarray): Confusion matrix.\n",
    "        classes (list or np.ndarray): List of class labels.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from itertools import cycle\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # === Left Subplot: ROC Curve ===\n",
    "    ax1 = axes[0]\n",
    "    if len(classes) == 2:\n",
    "        # Binary classification: plot ROC for the positive class only\n",
    "        pos_class = classes[1]  # Assuming the second class is the positive class\n",
    "        ax1.plot(fpr[1], tpr[1], color=model_color,\n",
    "                 lw=2, label=f'ROC curve (AUC = {roc_auc[1]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curve for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    else:\n",
    "        # Multi-class classification: plot ROC for each class using model_color and different line styles\n",
    "        line_styles = cycle(['-', '--', '-.', ':', '-', '--', '-.', ':', '-'])\n",
    "        for i, ls in zip(range(len(classes)), line_styles):\n",
    "            ax1.plot(fpr[i], tpr[i], color=model_color, linestyle=ls, lw=2,\n",
    "                     label=f'ROC curve of class {classes[i]} (AUC = {roc_auc[i]:0.2f})')\n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate')\n",
    "        ax1.set_ylabel('True Positive Rate')\n",
    "        ax1.set_title(f'ROC Curves for {model_name} Fold {fold+1}', color='black')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "    \n",
    "    # === Right Subplot: Confusion Matrix ===\n",
    "    ax2 = axes[1]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes, ax=ax2)\n",
    "    ax2.set_ylabel('Actual')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_title(f'Confusion Matrix for {model_name} Fold {fold+1}', color='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(fig)\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_learning_curves(history, model_name, fold, model_color):\n",
    "    \"\"\"\n",
    "    Plot the learning curves (loss and accuracy) for training and validation.\n",
    "    Only displays the figure inline without saving.\n",
    "\n",
    "    Args:\n",
    "        history (dict): Dictionary containing training and validation loss and accuracy.\n",
    "        model_name (str): Name of the model.\n",
    "        fold (int): Fold number.\n",
    "        model_color (str): Color assigned to the model.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'o-', color='grey', label='Training loss')\n",
    "    plt.plot(epochs, history['val_loss'], 's-', color=model_color, label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss for {model_name} Fold {fold+1}', color='black')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'o-', color='grey', label='Training accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 's-', color=model_color, label='Validation accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy for {model_name} Fold {fold+1}', color='black')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_aggregated_roc_curves(model_roc_data, num_classes, save_dir=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plot aggregated ROC curves for all models, including the Ensemble.\n",
    "\n",
    "    Args:\n",
    "        model_roc_data (dict): Dictionary where keys are model names and values are lists of (fpr, tpr) tuples per fold.\n",
    "        num_classes (int): Number of classes.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    # No longer saving the plots to disk; only display inline\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    colors = {\n",
    "        'ViT': 'crimson',\n",
    "        'MLP-Mixer': 'tomato',\n",
    "        'CvT': 'darkred',\n",
    "        'Swin': 'indigo',\n",
    "        'CaiT': 'royalblue',\n",
    "        'DeiT': 'cadetblue',\n",
    "        'DeiT3': 'dodgerblue',\n",
    "        'Twins_SVT': 'lightgreen',\n",
    "        'Twins_PCPVT': 'mediumseagreen',\n",
    "        'PiT': 'dimgrey',\n",
    "        'Ensemble': 'darkgoldenrod',\n",
    "        'Random': 'black'\n",
    "    }\n",
    "\n",
    "    for model_name, roc_list in model_roc_data.items():\n",
    "        if not roc_list:\n",
    "            continue  # Skip models with no ROC data\n",
    "\n",
    "        if model_name == 'Ensemble':\n",
    "            # For Ensemble, average the ROC curves across folds\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs = []\n",
    "            aucs = []\n",
    "            for fpr, tpr in roc_list:\n",
    "                interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(auc(fpr, tpr))\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            plt.plot(mean_fpr, mean_tpr, color=colors.get(model_name, 'black'),\n",
    "                     lw=2, label=f'{model_name} (AUC = {mean_auc:.2f})')\n",
    "        else:\n",
    "            # For individual models, plot each fold's ROC curve\n",
    "            for fpr, tpr in roc_list:\n",
    "                plt.plot(fpr, tpr, color=colors.get(model_name, 'black'),\n",
    "                         lw=1, alpha=0.3, label=f'{model_name} Fold ROC')\n",
    "\n",
    "            # Optionally, plot the mean ROC curve for each model\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "            tprs = []\n",
    "            aucs = []\n",
    "            for fpr, tpr in roc_list:\n",
    "                interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(auc(fpr, tpr))\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            plt.plot(mean_fpr, mean_tpr, color=colors.get(model_name, 'black'),\n",
    "                     lw=2, label=f'{model_name} Mean ROC (AUC = {mean_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Aggregated ROC Curves for All Models Including Ensemble')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the figure inline\n",
    "    display(plt.gcf())\n",
    "\n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_dir = \"/home/parlange/datasets/mini_sample/images\"\n",
    "    metadata_file = \"/home/parlange/datasets/mini_sample/metadata_catalog.fits\"\n",
    "\n",
    "    bands = ['g', 'r', 'i', 'z', 'y']\n",
    "    image_files = {\n",
    "        'g': 'image_catalog_g.fits',\n",
    "        'r': 'image_catalog_r.fits',\n",
    "        'i': 'image_catalog_i.fits',\n",
    "        'z': 'image_catalog_z.fits',\n",
    "        'y': 'image_catalog_y.fits'\n",
    "    }\n",
    "\n",
    "    band_data = []\n",
    "    shapes = []\n",
    "    for b in bands:\n",
    "        file_path = os.path.join(images_dir, image_files[b])\n",
    "        with fits.open(file_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "            print(f\"Shape for {b} band: {data.shape}\")\n",
    "            # Replace NaN and Inf with zeros\n",
    "            data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            band_data.append(data)\n",
    "            shapes.append(data.shape)\n",
    "\n",
    "    unique_shapes = set(shapes)\n",
    "    if len(unique_shapes) != 1:\n",
    "        raise ValueError(f\"Inconsistent shapes among bands: {unique_shapes}\")\n",
    "\n",
    "    X = np.stack(band_data, axis=1)\n",
    "    print(\"Final X shape:\", X.shape)\n",
    "\n",
    "    with fits.open(metadata_file) as hdul:\n",
    "        meta_data = hdul[1].data\n",
    "        y = np.array(meta_data['label'])\n",
    "        print(\"y shape:\", y.shape)\n",
    "\n",
    "    y = y.astype(np.int64)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()   # (N, 5, H, W)\n",
    "    y_tensor = torch.from_numpy(y).long()    # (N,)\n",
    "\n",
    "    # Check for remaining NaNs or Infs\n",
    "    if torch.isnan(X_tensor).any():\n",
    "        print(\"X_tensor contains NaN values. Replacing with 0.\")\n",
    "        X_tensor = torch.nan_to_num(X_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if torch.isinf(X_tensor).any():\n",
    "        print(\"X_tensor contains Inf values. Replacing with 0.\")\n",
    "        X_tensor = torch.nan_to_num(X_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Compute channel statistics\n",
    "    means, stds = compute_channel_stats(X_tensor)\n",
    "    print(\"Per-channel means:\", means)\n",
    "    print(\"Per-channel stds:\", stds)\n",
    "\n",
    "    # Check for NaN or Inf in means and stds\n",
    "    if torch.isnan(means).any() or torch.isnan(stds).any():\n",
    "        print(\"Computed means or stds contain NaN. Replacing with 0.5 and 0.5 respectively.\")\n",
    "        means = torch.where(torch.isnan(means), torch.tensor(0.5), means)\n",
    "        stds = torch.where(torch.isnan(stds), torch.tensor(0.5), stds)\n",
    "    if torch.isinf(means).any() or torch.isinf(stds).any():\n",
    "        print(\"Computed means or stds contain Inf. Replacing with 1.0 and 1.0 respectively.\")\n",
    "        means = torch.where(torch.isinf(means), torch.tensor(1.0), means)\n",
    "        stds = torch.where(torch.isinf(stds), torch.tensor(1.0), stds)\n",
    "\n",
    "    # Define training and validation transforms with normalization\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        RandomApply([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=30),\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.2)),\n",
    "            transforms.RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "        ], p=0.5),\n",
    "        transforms.Normalize(mean=means.tolist(),\n",
    "                             std=stds.tolist())\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=means.tolist(),\n",
    "                             std=stds.tolist())\n",
    "    ])\n",
    "\n",
    "    dataset = FITSDataset(X_tensor, y_tensor)\n",
    "    N = len(dataset)\n",
    "    num_classes = len(torch.unique(y_tensor))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Number of GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "    # List of models to train\n",
    "    model_names = ['ViT', 'CaiT', 'DeiT', 'DeiT3', 'Swin', \n",
    "                  'Twins_SVT', 'Twins_PCPVT', 'PiT', 'MLP-Mixer']\n",
    "\n",
    "    # Define per-model fine-tuning configurations with 'last_n_blocks' mode and exact last_n values\n",
    "    model_config = {\n",
    "        'ViT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},          # 12 blocks / 2 = 6\n",
    "        'CaiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 12},        # 24 blocks / 2 = 12\n",
    "        'DeiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},         # 12 blocks / 2 = 6\n",
    "        'DeiT3': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},        # 12 blocks / 2 = 6\n",
    "        'Swin': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},         # 12 blocks / 2 = 6\n",
    "        'Twins_SVT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},    # 12 blocks / 2 = 6\n",
    "        'Twins_PCPVT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 2},  # 4 blocks / 2 = 2\n",
    "        'PiT': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},          # 12 blocks / 2 = 6\n",
    "        'MLP-Mixer': {'fine_tune_mode': 'last_n_blocks', 'last_n': 6},    # 12 blocks / 2 = 6\n",
    "    }\n",
    "\n",
    "    k = 5\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # To store overall results\n",
    "    model_metrics = {model: {'auc_roc': [], 'f1': []} for model in model_names}\n",
    "    # To store ROC data for aggregated plotting\n",
    "    model_roc_data = {model: [] for model in model_names}\n",
    "\n",
    "    # Define your colors dictionary\n",
    "    colors = {\n",
    "        'ViT': 'crimson',\n",
    "        'MLP-Mixer': 'tomato',\n",
    "        'CvT': 'darkred',\n",
    "        'Swin': 'indigo',\n",
    "        'CaiT': 'royalblue',\n",
    "        'DeiT': 'cadetblue',\n",
    "        'DeiT3': 'dodgerblue',\n",
    "        'Twins_SVT': 'lightgreen',\n",
    "        'Twins_PCPVT': 'mediumseagreen',\n",
    "        'PiT': 'dimgrey',\n",
    "        'Ensemble': 'darkgoldenrod',\n",
    "        'Random': 'black'\n",
    "    }\n",
    "\n",
    "    # Initialize a dictionary to store predictions per fold across all models\n",
    "    fold_predictions = {fold: {'labels': None, 'probs': []} for fold in range(k)}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n==== Training Model: {model_name} ====\\n\")\n",
    "        fold_results = []\n",
    "        # Iterate through each fold\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(N), y_tensor.cpu().numpy())):\n",
    "            print(f\"\\n=== Fold {fold+1}/{k} for model {model_name} ===\")\n",
    "            print(f\"Training: {len(train_idx)}, Validation: {len(val_idx)}\")\n",
    "\n",
    "            train_subset = Subset(FITSDataset(X_tensor[train_idx], y_tensor[train_idx], transform=train_transform), range(len(train_idx)))\n",
    "            val_subset = Subset(FITSDataset(X_tensor[val_idx], y_tensor[val_idx], transform=val_transform), range(len(val_idx)))\n",
    "\n",
    "            pin_memory = torch.cuda.is_available()\n",
    "            train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4, pin_memory=pin_memory)\n",
    "            val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=4, pin_memory=pin_memory)\n",
    "\n",
    "            # Get model configuration\n",
    "            config = model_config.get(model_name, {'fine_tune_mode': 'classification_head', 'last_n': 6})\n",
    "            fine_tune_mode = config['fine_tune_mode']\n",
    "            last_n = config['last_n'] if config['last_n'] is not None else 6  # Default to 6 if not set\n",
    "\n",
    "            # Print the fine-tuning mode and last_n if applicable\n",
    "            if fine_tune_mode == 'last_n_blocks':\n",
    "                print(f\"Fine-tuning mode: {fine_tune_mode} with last_n={last_n}\")\n",
    "            else:\n",
    "                print(f\"Fine-tuning mode: {fine_tune_mode}\")\n",
    "\n",
    "            model = initialize_model(model_name, num_classes, pretrained=False, fine_tune_mode=fine_tune_mode, last_n=last_n)\n",
    "\n",
    "            model = model.to(device)\n",
    "            if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "                model = nn.DataParallel(model)\n",
    "                print(\"Model wrapped in DataParallel.\")\n",
    "\n",
    "            try:\n",
    "                history, all_labels_np, all_preds_np, all_preds_probs, auc_roc, f1 = train_one_fold(\n",
    "                    model, train_loader, val_loader, device, num_epochs=2, patience=1, fold=fold, model_name=model_name\n",
    "                )\n",
    "                fold_results.append((auc_roc, f1))\n",
    "                model_metrics[model_name]['auc_roc'].append(auc_roc)\n",
    "                model_metrics[model_name]['f1'].append(f1)\n",
    "\n",
    "                # Assign true labels to the fold if not already assigned\n",
    "                if fold_predictions[fold]['labels'] is None:\n",
    "                    fold_predictions[fold]['labels'] = all_labels_np\n",
    "\n",
    "                # Append the predicted probabilities of the current model to the fold\n",
    "                fold_predictions[fold]['probs'].append(all_preds_probs)\n",
    "\n",
    "                # Retrieve the model's color from the colors dictionary\n",
    "                model_color = colors.get(model_name, 'black')  # Default to 'black' if not found\n",
    "\n",
    "                # Plot learning curves (only display, no save)\n",
    "                plot_learning_curves(history, model_name, fold, model_color=model_color)\n",
    "\n",
    "                # Compute confusion matrix\n",
    "                cm = confusion_matrix(all_labels_np, all_preds_np)\n",
    "\n",
    "                # Compute ROC curves\n",
    "                # Binarize the labels for ROC\n",
    "                all_labels_binarized = label_binarize(all_labels_np, classes=np.arange(num_classes))\n",
    "                if all_labels_binarized.shape[1] == 1:\n",
    "                    # Handle binary classification case\n",
    "                    all_labels_binarized = np.hstack((1 - all_labels_binarized, all_labels_binarized))\n",
    "\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc_dict = dict()\n",
    "                for i in range(num_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(all_labels_binarized[:, i], all_preds_probs[:, i])\n",
    "                    roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "                # Store ROC data for aggregated plotting\n",
    "                model_roc_data[model_name].append((fpr, tpr))\n",
    "\n",
    "                # Plot combined metrics (ROC and Confusion Matrix) (only display, no save)\n",
    "                plot_combined_metrics(fpr, tpr, roc_auc_dict, cm, classes=np.arange(num_classes), \n",
    "                                      model_name=model_name, fold=fold, model_color=model_color)\n",
    "\n",
    "            except ValueError as e:\n",
    "                print(f\"Training stopped due to error: {e}\")\n",
    "                break  # Optionally, continue with next fold or model\n",
    "\n",
    "        if fold_results:\n",
    "            avg_auc = np.mean([res[0] for res in fold_results])\n",
    "            avg_f1 = np.mean([res[1] for res in fold_results])\n",
    "            print(f\"\\nResults for {model_name}: Average AUC-ROC: {avg_auc:.4f}, Average F1 Score: {avg_f1:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\nNo results for {model_name} due to training issues.\")\n",
    "\n",
    "    # After all models have been trained, compute the ensemble ROC curves\n",
    "    # Initialize a list to store ensemble ROC data\n",
    "    ensemble_roc_data = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        print(f\"\\nProcessing Ensemble for Fold {fold+1}/{k}\")\n",
    "        labels = fold_predictions[fold]['labels']\n",
    "        probs_list = fold_predictions[fold]['probs']  # List of arrays from different models\n",
    "\n",
    "        # Stack the probabilities to create a (num_models, num_samples, num_classes) array\n",
    "        stacked_probs = np.stack(probs_list, axis=0)  # Shape: (num_models, num_samples, num_classes)\n",
    "\n",
    "        # Compute the average predicted probabilities across models\n",
    "        ensemble_probs = np.mean(stacked_probs, axis=0)  # Shape: (num_samples, num_classes)\n",
    "\n",
    "        # Binarize the labels for ROC\n",
    "        labels_binarized = label_binarize(labels, classes=np.arange(num_classes))\n",
    "        if labels_binarized.shape[1] == 1:\n",
    "            # Handle binary classification case\n",
    "            labels_binarized = np.hstack((1 - labels_binarized, labels_binarized))\n",
    "\n",
    "        # Compute ROC curves for ensemble\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc_dict = dict()\n",
    "        for i in range(num_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(labels_binarized[:, i], ensemble_probs[:, i])\n",
    "            roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Append to ensemble ROC data\n",
    "        ensemble_roc_data.append((fpr, tpr, roc_auc_dict))\n",
    "\n",
    "    # Add Ensemble ROC data to model_roc_data\n",
    "    model_roc_data['Ensemble'] = []\n",
    "    for fold in range(k):\n",
    "        fpr, tpr, roc_auc_dict = ensemble_roc_data[fold]\n",
    "        model_roc_data['Ensemble'].append((fpr, tpr))\n",
    "\n",
    "    # After all models have been trained, create and display the rankings\n",
    "    ranking_auc = sorted(model_metrics.items(), key=lambda x: np.nanmean(x[1]['auc_roc']), reverse=True)\n",
    "    ranking_f1 = sorted(model_metrics.items(), key=lambda x: np.nanmean(x[1]['f1']), reverse=True)\n",
    "\n",
    "    # Create DataFrames for rankings\n",
    "    ranking_auc_df = pd.DataFrame(ranking_auc, columns=['Model', 'Metrics'])\n",
    "    ranking_auc_df['Average AUC-ROC'] = ranking_auc_df['Metrics'].apply(lambda x: np.nanmean(x['auc_roc']))\n",
    "    ranking_auc_df = ranking_auc_df.drop('Metrics', axis=1).sort_values(by='Average AUC-ROC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    ranking_f1_df = pd.DataFrame(ranking_f1, columns=['Model', 'Metrics'])\n",
    "    ranking_f1_df['Average F1 Score'] = ranking_f1_df['Metrics'].apply(lambda x: np.nanmean(x['f1']))\n",
    "    ranking_f1_df = ranking_f1_df.drop('Metrics', axis=1).sort_values(by='Average F1 Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Display the rankings in the notebook\n",
    "    print(\"\\n==== Model Ranking Based on AUC-ROC ====\")\n",
    "    display(ranking_auc_df)\n",
    "\n",
    "    print(\"\\n==== Model Ranking Based on F1 Score ====\")\n",
    "    display(ranking_f1_df)\n",
    "\n",
    "    # Plot aggregated ROC curves for all models, including Ensemble\n",
    "    print(\"\\n==== Plotting Aggregated ROC Curves for All Models Including Ensemble ====\")\n",
    "    plot_aggregated_roc_curves(model_roc_data, num_classes, save_dir=\"plots\")  # save_dir is unused now\n",
    "\n",
    "    # Optionally, save the ranking results to a file\n",
    "    with open(\"model_ranking.txt\", \"w\") as f:\n",
    "        f.write(\"Model Ranking Based on AUC-ROC:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(ranking_auc, start=1):\n",
    "            f.write(f\"{rank}. {model} - Average AUC-ROC: {np.nanmean(metrics['auc_roc']):.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nModel Ranking Based on F1 Score:\\n\")\n",
    "        for rank, (model, metrics) in enumerate(ranking_f1, start=1):\n",
    "            f.write(f\"{rank}. {model} - Average F1 Score: {np.nanmean(metrics['f1']):.4f}\\n\")\n",
    "    \n",
    "    print(\"\\nModel rankings have been saved to 'model_ranking.txt'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "vit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
